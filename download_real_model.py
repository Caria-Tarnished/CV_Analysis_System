#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½åŠ©æ‰‹
å¸®åŠ©ç”¨æˆ·ä¸‹è½½çœŸå®çš„FER2013é¢„è®­ç»ƒæ¨¡å‹
"""

import os
import sys
import torch
from download_models import SimpleCNN, download_or_create_model

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("=" * 70)
    print(" " * 20 + "è¡¨æƒ…è¯†åˆ«é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½åŠ©æ‰‹")
    print("=" * 70)
    print()

def show_model_sources():
    """æ˜¾ç¤ºå¯ç”¨çš„æ¨¡å‹ä¸‹è½½æº"""
    print("ğŸ“¦ å¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½æºï¼š\n")
    
    sources = [
        {
            "name": "GitHub - FER2013 PyTorch",
            "url": "https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch",
            "description": "æµè¡Œçš„FER2013 PyTorchå®ç°",
            "steps": [
                "1. è®¿é—®ä¸Šè¿°GitHubä»“åº“",
                "2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ (é€šå¸¸æ˜¯.pthæˆ–.ptæ–‡ä»¶)",
                "3. å°†æ–‡ä»¶é‡å‘½åä¸º 'emotion_model.pth'",
                "4. æ”¾åˆ° 'models' ç›®å½•ä¸‹"
            ]
        },
        {
            "name": "Hugging Face - Emotion Recognition",
            "url": "https://huggingface.co/models?search=fer2013",
            "description": "Hugging Faceæ¨¡å‹åº“ä¸­çš„FER2013æ¨¡å‹",
            "steps": [
                "1. è®¿é—®Hugging Faceå¹¶æœç´¢ 'fer2013'",
                "2. é€‰æ‹©åˆé€‚çš„PyTorchæ¨¡å‹",
                "3. ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶",
                "4. æŒ‰ç…§æ¨¡å‹è¯´æ˜è¿›è¡Œæ ¼å¼è½¬æ¢ï¼ˆå¦‚éœ€è¦ï¼‰",
                "5. ä¿å­˜ä¸º 'models/emotion_model.pth'"
            ]
        },
        {
            "name": "Google Drive - å…±äº«æ¨¡å‹",
            "url": "æœç´¢: FER2013 pretrained model site:drive.google.com",
            "description": "ç ”ç©¶äººå‘˜åˆ†äº«çš„é¢„è®­ç»ƒæ¨¡å‹",
            "steps": [
                "1. åœ¨Googleæœç´¢ä¸­ä½¿ç”¨ä¸Šè¿°æœç´¢è¯",
                "2. æ‰¾åˆ°å¯ä¿¡çš„å…±äº«é“¾æ¥",
                "3. ä¸‹è½½æ¨¡å‹æ–‡ä»¶",
                "4. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§",
                "5. ä¿å­˜ä¸º 'models/emotion_model.pth'"
            ]
        },
        {
            "name": "ç™¾åº¦ç½‘ç›˜ - å›½å†…èµ„æº",
            "url": "æœç´¢: FER2013 é¢„è®­ç»ƒæ¨¡å‹ ç™¾åº¦ç½‘ç›˜",
            "description": "å›½å†…åˆ†äº«çš„æ¨¡å‹èµ„æºï¼ˆé€Ÿåº¦è¾ƒå¿«ï¼‰",
            "steps": [
                "1. åœ¨ç™¾åº¦æœç´¢ç›¸å…³å…³é”®è¯",
                "2. æ‰¾åˆ°å¯é çš„åˆ†äº«é“¾æ¥",
                "3. ä¸‹è½½æ¨¡å‹æ–‡ä»¶",
                "4. ä¿å­˜ä¸º 'models/emotion_model.pth'"
            ]
        }
    ]
    
    for i, source in enumerate(sources, 1):
        print(f"[{i}] {source['name']}")
        print(f"    ğŸ”— {source['url']}")
        print(f"    ğŸ“ {source['description']}")
        print(f"    \n    ä¸‹è½½æ­¥éª¤ï¼š")
        for step in source['steps']:
            print(f"    {step}")
        print()

def check_current_model():
    """æ£€æŸ¥å½“å‰æ¨¡å‹çŠ¶æ€"""
    model_path = "models/emotion_model.pth"
    
    print("\n" + "=" * 70)
    print("ğŸ“ å½“å‰æ¨¡å‹çŠ¶æ€æ£€æŸ¥")
    print("=" * 70 + "\n")
    
    if os.path.exists(model_path):
        print(f"âœ“ å‘ç°æ¨¡å‹æ–‡ä»¶: {model_path}")
        
        try:
            # åŠ è½½å¹¶æ£€æŸ¥æ¨¡å‹
            checkpoint = torch.load(model_path, map_location='cpu')
            
            if isinstance(checkpoint, dict):
                print(f"âœ“ æ¨¡å‹ç±»å‹: {checkpoint.get('model_type', 'æœªçŸ¥')}")
                print(f"âœ“ æ¨¡å‹ç‰ˆæœ¬: {checkpoint.get('model_version', 'v1')}")
                
                if 'created_by' in checkpoint:
                    print(f"âœ“ åˆ›å»ºå·¥å…·: {checkpoint['created_by']}")
                    if checkpoint['created_by'] == 'download_models.py':
                        print("  âš ï¸  è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿæ¨¡å‹ï¼Œå»ºè®®ä¸‹è½½çœŸå®çš„é¢„è®­ç»ƒæ¨¡å‹ä»¥è·å¾—æ›´å¥½æ•ˆæœ")
                    
                if 'note' in checkpoint:
                    print(f"âœ“ å¤‡æ³¨: {checkpoint['note']}")
                    
                # æ£€æŸ¥æ¨¡å‹å¤§å°
                file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
                print(f"âœ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                
                if file_size < 1:
                    print("  âš ï¸  æ–‡ä»¶è¾ƒå°ï¼Œå¯èƒ½ä¸æ˜¯å®Œæ•´çš„é¢„è®­ç»ƒæ¨¡å‹")
                else:
                    print("  âœ“ æ–‡ä»¶å¤§å°åˆç†")
                    
            else:
                print("âœ“ æ¨¡å‹æ ¼å¼: ç›´æ¥ä¿å­˜çš„æ¨¡å‹å¯¹è±¡")
                file_size = os.path.getsize(model_path) / (1024 * 1024)
                print(f"âœ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                
        except Exception as e:
            print(f"âœ— æ¨¡å‹æ–‡ä»¶å¯èƒ½æŸå: {e}")
            
    else:
        print(f"âœ— æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        print("  éœ€è¦ä¸‹è½½æˆ–åˆ›å»ºæ¨¡å‹")

def create_improved_model():
    """åˆ›å»ºæ”¹è¿›çš„æ¨¡å‹"""
    print("\n" + "=" * 70)
    print("ğŸ”§ åˆ›å»ºæ”¹è¿›ç‰ˆæ¨¡æ‹Ÿæ¨¡å‹")
    print("=" * 70 + "\n")
    
    print("æ­£åœ¨åˆ›å»ºæ”¹è¿›çš„æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å‹...")
    print("æ³¨æ„: è¿™ä¸æ˜¯çœŸå®çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†æ¯”éšæœºæƒé‡æ•ˆæœå¥½")
    print()
    
    model_path = download_or_create_model()
    print(f"\nâœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    return model_path

def show_integration_instructions():
    """æ˜¾ç¤ºå¦‚ä½•é›†æˆä¸‹è½½çš„æ¨¡å‹"""
    print("\n" + "=" * 70)
    print("ğŸ“– æ¨¡å‹é›†æˆè¯´æ˜")
    print("=" * 70 + "\n")
    
    print("å°†ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶æ”¾åˆ°æ­£ç¡®ä½ç½®åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨å®ƒï¼š")
    print()
    print("1. ç¡®ä¿æ¨¡å‹æ–‡ä»¶å‘½åä¸º: emotion_model.pth")
    print("2. æ”¾åˆ°ç›®å½•: CV_Analysis_System/models/")
    print("3. å®Œæ•´è·¯å¾„åº”ä¸º: CV_Analysis_System/models/emotion_model.pth")
    print()
    print("å¦‚æœæ¨¡å‹æ ¼å¼ä¸å…¼å®¹ï¼Œå¯èƒ½éœ€è¦è½¬æ¢ï¼š")
    print()
    print("```python")
    print("import torch")
    print("from emotion_recognizer import SimpleCNN")
    print()
    print("# åŠ è½½ä½ çš„æ¨¡å‹")
    print("model = SimpleCNN()")
    print("# åŠ è½½æƒé‡ï¼ˆæ ¹æ®å®é™…æ ¼å¼è°ƒæ•´ï¼‰")
    print("model.load_state_dict(torch.load('your_model.pth'))")
    print()
    print("# ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼")
    print("checkpoint = {")
    print("    'model_state_dict': model.state_dict(),")
    print("    'model_type': 'SimpleCNN',")
    print("    'num_classes': 7")
    print("}")
    print("torch.save(checkpoint, 'models/emotion_model.pth')")
    print("```")

def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
        print("[1] æŸ¥çœ‹é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½æº")
        print("[2] æ£€æŸ¥å½“å‰æ¨¡å‹çŠ¶æ€")
        print("[3] åˆ›å»ºæ”¹è¿›ç‰ˆæ¨¡æ‹Ÿæ¨¡å‹ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰")
        print("[4] æŸ¥çœ‹æ¨¡å‹é›†æˆè¯´æ˜")
        print("[0] é€€å‡º")
        print()
        
        choice = input("è¯·è¾“å…¥é€‰é¡¹ (0-4): ").strip()
        
        if choice == '1':
            show_model_sources()
            
        elif choice == '2':
            check_current_model()
            
        elif choice == '3':
            create_improved_model()
            
        elif choice == '4':
            show_integration_instructions()
            
        elif choice == '0':
            print("\nå†è§ï¼")
            break
    
    else:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
